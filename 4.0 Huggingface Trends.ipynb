{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends = ['model', 'dataset']\n",
    "trend_data = {}\n",
    "for trend in trends:\n",
    "    url = f'https://huggingface.co/api/trending?type={trend}'\n",
    "\n",
    "    response = requests.get(url).json()\n",
    "    trend_data[f'{trend}s'] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'https://huggingface.co/api/posts?sort=trending'\n",
    "\n",
    "response = requests.get(url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct post from response\n",
    "trending_posts = []\n",
    "\n",
    "posts = response['socialPosts']\n",
    "for post in posts:\n",
    "    content = ''.join([line['raw'] for line in post['content']])\n",
    "\n",
    "    post_with_details = {}\n",
    "    post_with_details['content'] = content\n",
    "    post_with_details['publishedAt'] = post['publishedAt']\n",
    "    post_with_details['author'] = post['author']['name']\n",
    "    trending_posts.append(post_with_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hunyuan3D-1 - SOTA Open Source Text-to-3D and Image-to-3D - 1-Click Install and use both Locally on Windows and on Cloud - RunPod and Massed Compute\n",
      "\n",
      "Automatic Installers\n",
      "Works amazing on 24 GB GPUs\n",
      "Files > https://www.patreon.com/posts/115412205\n",
      "\n",
      "So what is Hunyuan3D-1\n",
      "Official repo : https://github.com/tencent/Hunyuan3D-1\n",
      "On Hugging Face : https://huggingface.co/tencent/Hunyuan3D-1\n",
      "\n",
      "Tencent Hunyuan3D-1.0: A Unified Framework for Text-to-3D and Image-to-3D Generation\n",
      "\n",
      "Abstract\n",
      "\n",
      "While 3D generative models have greatly improved artists' workflows, the existing diffusion models for 3D generation suffer from slow generation and poor generalization. To address this issue, we propose a two-stage approach named Hunyuan3D-1.0 including a lite version and a standard version, that both support text- and image-conditioned generation.\n",
      "\n",
      "In the first stage, we employ a multi-view diffusion model that efficiently generates multi-view RGB in approximately 4 seconds. These multi-view images capture rich details of the 3D asset from different viewpoints, relaxing the tasks from single-view to multi-view reconstruction. In the second stage, we introduce a feed-forward reconstruction model that rapidly and faithfully reconstructs the 3D asset given the generated multi-view images in approximately 7 seconds. The reconstruction network learns to handle noises and in-consistency introduced by the multi-view diffusion and leverages the available information from the condition image to efficiently recover the 3D structure.\n",
      "\n",
      "Our framework involves the text-to-image model, i.e., Hunyuan-DiT, making it a unified framework to support both text- and image-conditioned 3D generation. Our standard version has 3x more parameters than our lite and other existing model. Our Hunyuan3D-1.0 achieves an impressive balance between speed and quality, significantly reducing generation time while maintaining the quality and diversity of the produced assets.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(trending_posts[1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_data['trending_posts'] = trending_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': {'recentlyTrending': [{'repoData': {'author': 'Etched',\n",
       "     'authorData': {'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/61ac8f8a00d01045fca0ad2f/b5V8S2PWSLuxdz-LFyEaS.jpeg',\n",
       "      'fullname': 'Etched',\n",
       "      'name': 'Etched',\n",
       "      'type': 'org',\n",
       "      'isHf': False,\n",
       "      'isMod': False,\n",
       "      'isEnterprise': False,\n",
       "      'followerCount': 116},\n",
       "     'downloads': 3242,\n",
       "     'gated': 'auto',\n",
       "     'id': 'Etched/oasis-500m',\n",
       "     'inference': 'pipeline-not-detected',\n",
       "     'isLikedByUser': False,\n",
       "     'lastModified': '2024-11-04T20:26:21.000Z',\n",
       "     'likes': 288,\n",
       "     'private': False,\n",
       "     'repoType': 'model'},\n",
       "    'repoType': 'model'},\n",
       "   {'repoData': {'author': 'tencent',\n",
       "     'authorData': {'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/5dd96eb166059660ed1ee413/Lp3m-XLpjQGwBItlvn69q.png',\n",
       "      'fullname': 'Tencent',\n",
       "      'name': 'tencent',\n",
       "      'type': 'org',\n",
       "      'isHf': False,\n",
       "      'isMod': False,\n",
       "      'isEnterprise': False,\n",
       "      'followerCount': 288},\n",
       "     'downloads': 40,\n",
       "     'gated': False,\n",
       "     'id': 'tencent/Tencent-Hunyuan-Large',\n",
       "     'inference': 'cold',\n",
       "     'isLikedByUser': False,\n",
       "     'lastModified': '2024-11-07T09:35:24.000Z',\n",
       "     'likes': 285,\n",
       "     'pipeline_tag': 'text-generation',\n",
       "     'private': False,\n",
       "     'repoType': 'model',\n",
       "     'widgetOutputUrls': []},\n",
       "    'repoType': 'model'},\n",
       "   {'repoData': {'author': 'microsoft',\n",
       "     'authorData': {'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1583646260758-5e64858c87403103f9f1055d.png',\n",
       "      'fullname': 'Microsoft',\n",
       "      'name': 'microsoft',\n",
       "      'type': 'org',\n",
       "      'isHf': False,\n",
       "      'isMod': False,\n",
       "      'isEnterprise': False,\n",
       "      'followerCount': 4693},\n",
       "     'downloads': 5498,\n",
       "     'gated': False,\n",
       "     'id': 'microsoft/OmniParser',\n",
       "     'inference': 'pipeline-library-pair-not-supported',\n",
       "     'isLikedByUser': False,\n",
       "     'lastModified': '2024-11-01T17:50:58.000Z',\n",
       "     'likes': 1061,\n",
       "     'pipeline_tag': 'image-text-to-text',\n",
       "     'private': False,\n",
       "     'repoType': 'model'},\n",
       "    'repoType': 'model'},\n",
       "   {'repoData': {'author': 'HuggingFaceTB',\n",
       "     'authorData': {'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/651e96991b97c9f33d26bde6/e4VK7uW5sTeCYupD0s_ob.png',\n",
       "      'fullname': 'Hugging Face TB Research',\n",
       "      'name': 'HuggingFaceTB',\n",
       "      'type': 'org',\n",
       "      'isHf': False,\n",
       "      'isMod': False,\n",
       "      'isEnterprise': True,\n",
       "      'followerCount': 329},\n",
       "     'downloads': 20073,\n",
       "     'gated': False,\n",
       "     'id': 'HuggingFaceTB/SmolLM2-1.7B-Instruct',\n",
       "     'inference': 'loading',\n",
       "     'isLikedByUser': False,\n",
       "     'lastModified': '2024-11-05T09:53:40.000Z',\n",
       "     'likes': 246,\n",
       "     'pipeline_tag': 'text-generation',\n",
       "     'private': False,\n",
       "     'repoType': 'model',\n",
       "     'widgetOutputUrls': []},\n",
       "    'repoType': 'model'},\n",
       "   {'repoData': {'author': 'black-forest-labs',\n",
       "     'authorData': {'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/62cfefa74b3e8dc1e32e38bf/GgkglHn3sIo6C5XGTtZSs.png',\n",
       "      'fullname': 'Black Forest Labs',\n",
       "      'name': 'black-forest-labs',\n",
       "      'type': 'org',\n",
       "      'isHf': False,\n",
       "      'isMod': False,\n",
       "      'isEnterprise': False,\n",
       "      'followerCount': 1644},\n",
       "     'downloads': 1269791,\n",
       "     'gated': 'auto',\n",
       "     'id': 'black-forest-labs/FLUX.1-dev',\n",
       "     'inference': 'warm',\n",
       "     'isLikedByUser': False,\n",
       "     'lastModified': '2024-08-16T14:38:19.000Z',\n",
       "     'likes': 6127,\n",
       "     'pipeline_tag': 'text-to-image',\n",
       "     'private': False,\n",
       "     'repoType': 'model'},\n",
       "    'repoType': 'model'},\n",
       "   {'repoData': {'author': 'stabilityai',\n",
       "     'authorData': {'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/643feeb67bc3fbde1385cc25/7vmYr2XwVcPtkLzac_jxQ.png',\n",
       "      'fullname': 'Stability AI',\n",
       "      'name': 'stabilityai',\n",
       "      'type': 'org',\n",
       "      'isHf': False,\n",
       "      'isMod': False,\n",
       "      'isEnterprise': True,\n",
       "      'followerCount': 5799},\n",
       "     'downloads': 178198,\n",
       "     'gated': 'auto',\n",
       "     'id': 'stabilityai/stable-diffusion-3.5-large',\n",
       "     'inference': 'warm',\n",
       "     'isLikedByUser': False,\n",
       "     'lastModified': '2024-10-22T14:36:33.000Z',\n",
       "     'likes': 1069,\n",
       "     'pipeline_tag': 'text-to-image',\n",
       "     'private': False,\n",
       "     'repoType': 'model'},\n",
       "    'repoType': 'model'},\n",
       "   {'repoData': {'author': 'genmo',\n",
       "     'authorData': {'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/62f678c42e53c2efd33c23a0/gPtbW3Y65TmjupvWW-fbS.png',\n",
       "      'fullname': 'Genmo',\n",
       "      'name': 'genmo',\n",
       "      'type': 'org',\n",
       "      'isHf': False,\n",
       "      'isMod': False,\n",
       "      'isEnterprise': False,\n",
       "      'followerCount': 235},\n",
       "     'downloads': 1543,\n",
       "     'gated': False,\n",
       "     'id': 'genmo/mochi-1-preview',\n",
       "     'inference': 'pipeline-library-pair-not-supported',\n",
       "     'isLikedByUser': False,\n",
       "     'lastModified': '2024-11-01T03:38:05.000Z',\n",
       "     'likes': 864,\n",
       "     'pipeline_tag': 'text-to-video',\n",
       "     'private': False,\n",
       "     'repoType': 'model'},\n",
       "    'repoType': 'model'},\n",
       "   {'repoData': {'author': 'nvidia',\n",
       "     'authorData': {'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1613114437487-60262a8e0703121c822a80b6.png',\n",
       "      'fullname': 'NVIDIA',\n",
       "      'name': 'nvidia',\n",
       "      'type': 'org',\n",
       "      'isHf': False,\n",
       "      'isMod': False,\n",
       "      'isEnterprise': False,\n",
       "      'followerCount': 3161},\n",
       "     'downloads': 194838,\n",
       "     'gated': False,\n",
       "     'id': 'nvidia/Llama-3.1-Nemotron-70B-Instruct-HF',\n",
       "     'inference': 'explicit-opt-out',\n",
       "     'isLikedByUser': False,\n",
       "     'lastModified': '2024-10-25T04:12:17.000Z',\n",
       "     'likes': 1505,\n",
       "     'pipeline_tag': 'text-generation',\n",
       "     'private': False,\n",
       "     'repoType': 'model',\n",
       "     'widgetOutputUrls': []},\n",
       "    'repoType': 'model'},\n",
       "   {'repoData': {'author': 'fishaudio',\n",
       "     'authorData': {'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/63124e13b843665ddc69837a/BKg3eeWpt6woeulf_FXND.png',\n",
       "      'fullname': 'Fish Audio',\n",
       "      'name': 'fishaudio',\n",
       "      'type': 'org',\n",
       "      'isHf': False,\n",
       "      'isMod': False,\n",
       "      'isEnterprise': False,\n",
       "      'followerCount': 138},\n",
       "     'downloads': 369,\n",
       "     'gated': False,\n",
       "     'id': 'fishaudio/fish-agent-v0.1-3b',\n",
       "     'inference': 'explicit-opt-out',\n",
       "     'isLikedByUser': False,\n",
       "     'lastModified': '2024-11-01T16:39:56.000Z',\n",
       "     'likes': 143,\n",
       "     'pipeline_tag': 'audio-to-audio',\n",
       "     'private': False,\n",
       "     'repoType': 'model'},\n",
       "    'repoType': 'model'},\n",
       "   {'repoData': {'author': 'OuteAI',\n",
       "     'authorData': {'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/661faec40d6d77fb4baf494c/DggPdMP8qp34wyy6bnSkk.png',\n",
       "      'fullname': 'OuteAI',\n",
       "      'name': 'OuteAI',\n",
       "      'type': 'org',\n",
       "      'isHf': False,\n",
       "      'isMod': False,\n",
       "      'isEnterprise': False,\n",
       "      'followerCount': 58},\n",
       "     'downloads': 2203,\n",
       "     'gated': False,\n",
       "     'id': 'OuteAI/OuteTTS-0.1-350M',\n",
       "     'inference': 'library-not-detected',\n",
       "     'isLikedByUser': False,\n",
       "     'lastModified': '2024-11-06T16:58:29.000Z',\n",
       "     'likes': 141,\n",
       "     'pipeline_tag': 'text-to-speech',\n",
       "     'private': False,\n",
       "     'repoType': 'model'},\n",
       "    'repoType': 'model'}]},\n",
       " 'datasets': {'recentlyTrending': [{'repoData': {'author': 'fka',\n",
       "     'downloads': 8809,\n",
       "     'gated': False,\n",
       "     'id': 'fka/awesome-chatgpt-prompts',\n",
       "     'isLikedByUser': False,\n",
       "     'lastModified': '2024-09-03T21:28:41.000Z',\n",
       "     'likes': 6148,\n",
       "     'datasetsServerInfo': {'viewer': 'viewer',\n",
       "      'numRows': 170,\n",
       "      'libraries': ['datasets', 'pandas', 'mlcroissant', 'polars'],\n",
       "      'formats': ['csv'],\n",
       "      'modalities': ['text']},\n",
       "     'private': False,\n",
       "     'repoType': 'dataset'},\n",
       "    'repoType': 'dataset'},\n",
       "   {'repoData': {'author': 'Spawning',\n",
       "     'downloads': 5982,\n",
       "     'gated': False,\n",
       "     'id': 'Spawning/PD12M',\n",
       "     'isLikedByUser': False,\n",
       "     'lastModified': '2024-10-31T15:25:49.000Z',\n",
       "     'likes': 87,\n",
       "     'datasetsServerInfo': {'viewer': 'viewer',\n",
       "      'numRows': 12400094,\n",
       "      'libraries': ['datasets', 'dask', 'mlcroissant', 'polars'],\n",
       "      'formats': ['parquet'],\n",
       "      'modalities': ['image', 'tabular', 'text']},\n",
       "     'private': False,\n",
       "     'repoType': 'dataset'},\n",
       "    'repoType': 'dataset'},\n",
       "   {'repoData': {'author': 'qq8933',\n",
       "     'downloads': 189,\n",
       "     'gated': False,\n",
       "     'id': 'qq8933/OpenLongCoT-Pretrain',\n",
       "     'isLikedByUser': False,\n",
       "     'lastModified': '2024-10-28T13:50:37.000Z',\n",
       "     'likes': 37,\n",
       "     'datasetsServerInfo': {'viewer': 'viewer',\n",
       "      'numRows': 102906,\n",
       "      'libraries': ['datasets', 'pandas', 'mlcroissant', 'polars'],\n",
       "      'formats': ['parquet'],\n",
       "      'modalities': ['text']},\n",
       "     'private': False,\n",
       "     'repoType': 'dataset'},\n",
       "    'repoType': 'dataset'},\n",
       "   {'repoData': {'author': 'neuralwork',\n",
       "     'downloads': 4090,\n",
       "     'gated': False,\n",
       "     'id': 'neuralwork/arxiver',\n",
       "     'isLikedByUser': False,\n",
       "     'lastModified': '2024-11-01T21:18:04.000Z',\n",
       "     'likes': 334,\n",
       "     'datasetsServerInfo': {'viewer': 'viewer',\n",
       "      'numRows': 63357,\n",
       "      'libraries': ['datasets', 'pandas', 'mlcroissant', 'polars'],\n",
       "      'formats': ['parquet'],\n",
       "      'modalities': ['text']},\n",
       "     'private': False,\n",
       "     'repoType': 'dataset'},\n",
       "    'repoType': 'dataset'},\n",
       "   {'repoData': {'author': 'amphion',\n",
       "     'downloads': 50876,\n",
       "     'gated': 'auto',\n",
       "     'id': 'amphion/Emilia-Dataset',\n",
       "     'isLikedByUser': False,\n",
       "     'lastModified': '2024-09-06T13:29:55.000Z',\n",
       "     'likes': 147,\n",
       "     'datasetsServerInfo': {'viewer': 'viewer-partial',\n",
       "      'numRows': 52941108,\n",
       "      'libraries': ['datasets', 'webdataset', 'mlcroissant'],\n",
       "      'formats': ['webdataset'],\n",
       "      'modalities': ['audio', 'text']},\n",
       "     'private': False,\n",
       "     'repoType': 'dataset'},\n",
       "    'repoType': 'dataset'},\n",
       "   {'repoData': {'author': 'BAAI',\n",
       "     'downloads': 40206,\n",
       "     'gated': 'auto',\n",
       "     'id': 'BAAI/Infinity-MM',\n",
       "     'isLikedByUser': False,\n",
       "     'lastModified': '2024-11-05T06:57:13.000Z',\n",
       "     'likes': 55,\n",
       "     'datasetsServerInfo': {'viewer': 'viewer-partial',\n",
       "      'numRows': 687616320,\n",
       "      'libraries': ['datasets', 'webdataset', 'mlcroissant'],\n",
       "      'formats': ['webdataset'],\n",
       "      'modalities': ['image', 'text']},\n",
       "     'private': False,\n",
       "     'repoType': 'dataset'},\n",
       "    'repoType': 'dataset'},\n",
       "   {'repoData': {'author': 'wyu1',\n",
       "     'downloads': 31007,\n",
       "     'gated': False,\n",
       "     'id': 'wyu1/Leopard-Instruct',\n",
       "     'isLikedByUser': False,\n",
       "     'lastModified': '2024-10-31T04:57:19.000Z',\n",
       "     'likes': 22,\n",
       "     'datasetsServerInfo': {'viewer': 'viewer-partial',\n",
       "      'numRows': 1027123,\n",
       "      'libraries': ['datasets', 'dask', 'mlcroissant', 'polars'],\n",
       "      'formats': ['parquet'],\n",
       "      'modalities': ['image', 'text']},\n",
       "     'private': False,\n",
       "     'repoType': 'dataset'},\n",
       "    'repoType': 'dataset'},\n",
       "   {'repoData': {'author': 'GAIR',\n",
       "     'downloads': 784,\n",
       "     'gated': False,\n",
       "     'id': 'GAIR/o1-journey',\n",
       "     'isLikedByUser': False,\n",
       "     'lastModified': '2024-10-16T00:42:02.000Z',\n",
       "     'likes': 61,\n",
       "     'datasetsServerInfo': {'viewer': 'viewer',\n",
       "      'numRows': 327,\n",
       "      'libraries': ['datasets', 'pandas', 'mlcroissant', 'polars'],\n",
       "      'formats': ['json'],\n",
       "      'modalities': ['text']},\n",
       "     'private': False,\n",
       "     'repoType': 'dataset'},\n",
       "    'repoType': 'dataset'},\n",
       "   {'repoData': {'author': 'beomi',\n",
       "     'downloads': 33,\n",
       "     'gated': 'auto',\n",
       "     'id': 'beomi/KoAlpaca-RealQA',\n",
       "     'isLikedByUser': False,\n",
       "     'lastModified': '2024-11-03T07:00:13.000Z',\n",
       "     'likes': 19,\n",
       "     'datasetsServerInfo': {'viewer': 'viewer',\n",
       "      'numRows': 18524,\n",
       "      'libraries': ['datasets', 'pandas', 'mlcroissant', 'polars'],\n",
       "      'formats': ['parquet'],\n",
       "      'modalities': ['text']},\n",
       "     'private': False,\n",
       "     'repoType': 'dataset'},\n",
       "    'repoType': 'dataset'},\n",
       "   {'repoData': {'author': 'argilla',\n",
       "     'downloads': 257,\n",
       "     'gated': False,\n",
       "     'id': 'argilla/Synth-APIGen-v0.1',\n",
       "     'isLikedByUser': False,\n",
       "     'lastModified': '2024-10-10T11:52:03.000Z',\n",
       "     'likes': 32,\n",
       "     'datasetsServerInfo': {'viewer': 'viewer',\n",
       "      'numRows': 49402,\n",
       "      'libraries': ['datasets', 'pandas', 'mlcroissant', 'polars'],\n",
       "      'formats': ['parquet'],\n",
       "      'modalities': ['text']},\n",
       "     'private': False,\n",
       "     'repoType': 'dataset'},\n",
       "    'repoType': 'dataset'}]},\n",
       " 'trending_posts': [{'content': 'New Style, New Mix, New Drop üß§\\n\\nüß®Flux LoRA DLC: https://huggingface.co/spaces/prithivMLmods/FLUX-LoRA-DLC\\n\\nüéÜGlowing-Body: https://huggingface.co/prithivMLmods/Glowing-Body-Flux-LoRA\\nüéÜElectric-Blue: https://huggingface.co/prithivMLmods/Electric-Blue-Flux-LoRA\\nüéÜIntense-Red: https://huggingface.co/prithivMLmods/Intense-Red-Flux-LoRA\\nüéÜClouds-Illusion: https://huggingface.co/prithivMLmods/Clouds-Illusion-Flux-LoRA\\nüéÜDigital-Yellow: https://huggingface.co/prithivMLmods/Digital-Yellow-Flux-LoRA\\n\\nüß®Flux LoRA Collection: https://huggingface.co/collections/prithivMLmods/flux-lora-collections-66dd5908be2206cfaa8519be\\n\\n.\\n.\\n.\\n@prithivMLmods \\n',\n",
       "   'publishedAt': '2024-11-04T10:35:40.000Z',\n",
       "   'author': 'prithivMLmods'},\n",
       "  {'content': \"Hunyuan3D-1 - SOTA Open Source Text-to-3D and Image-to-3D - 1-Click Install and use both Locally on Windows and on Cloud - RunPod and Massed Compute\\n\\nAutomatic Installers\\nWorks amazing on 24 GB GPUs\\nFiles > https://www.patreon.com/posts/115412205\\n\\nSo what is Hunyuan3D-1\\nOfficial repo : https://github.com/tencent/Hunyuan3D-1\\nOn Hugging Face : https://huggingface.co/tencent/Hunyuan3D-1\\n\\nTencent Hunyuan3D-1.0: A Unified Framework for Text-to-3D and Image-to-3D Generation\\n\\nAbstract\\n\\nWhile 3D generative models have greatly improved artists' workflows, the existing diffusion models for 3D generation suffer from slow generation and poor generalization. To address this issue, we propose a two-stage approach named Hunyuan3D-1.0 including a lite version and a standard version, that both support text- and image-conditioned generation.\\n\\nIn the first stage, we employ a multi-view diffusion model that efficiently generates multi-view RGB in approximately 4 seconds. These multi-view images capture rich details of the 3D asset from different viewpoints, relaxing the tasks from single-view to multi-view reconstruction. In the second stage, we introduce a feed-forward reconstruction model that rapidly and faithfully reconstructs the 3D asset given the generated multi-view images in approximately 7 seconds. The reconstruction network learns to handle noises and in-consistency introduced by the multi-view diffusion and leverages the available information from the condition image to efficiently recover the 3D structure.\\n\\nOur framework involves the text-to-image model, i.e., Hunyuan-DiT, making it a unified framework to support both text- and image-conditioned 3D generation. Our standard version has 3x more parameters than our lite and other existing model. Our Hunyuan3D-1.0 achieves an impressive balance between speed and quality, significantly reducing generation time while maintaining the quality and diversity of the produced assets.\\n\\n\\n\\n\\n\",\n",
       "   'publishedAt': '2024-11-06T08:53:32.000Z',\n",
       "   'author': 'MonsterMMORPG'},\n",
       "  {'content': 'Effortlessly stay up-to-date with AI research trends using a new AI tool, \"AI Paper Reviewer\" !! \\n\\nIt analyzes a list of Hugging Face Daily Papers(w/ @akhaliq) and turn them into insightful blog posts. This project leverages Gemini models (1.5 Pro, 1.5 Flash, and 1.5 Flash-8B) for content generation and Upstage Document Parse for parsing the layout and contents. \\nblog link: https://deep-diver.github.io/ai-paper-reviewer/\\n\\nAlso, here is the link of GitHub repository for parsing and generating pipeline. By using this, you can easily build your own GitHub static pages based on any arXiv papers with your own interest!\\n: https://github.com/deep-diver/paper-reviewer',\n",
       "   'publishedAt': '2024-11-06T05:02:54.000Z',\n",
       "   'author': 'chansung'},\n",
       "  {'content': 'New app built based on https://huggingface.co/docs/transformers.js and https://huggingface.co/collections/minishlab/potion-6721e0abd4ea41881417f062!\\nIt uses the super performant CPU-only models to calculate semantic similarity fully client-side based on Excel or CSV tables. \\n- App: https://do-me.github.io/semantic-similarity-table/\\n- Code: https://github.com/do-me/semantic-similarity-table\\n\\n',\n",
       "   'publishedAt': '2024-11-06T14:35:56.000Z',\n",
       "   'author': 'do-me'},\n",
       "  {'content': \"Just tested Argilla's new data annotation feature - it's a game changer for AI project quality. \\n\\nUpload CSVs, work with published datasets, or improve existing ones directly on HuggingFace Hub. Setup took < 2 minutes, no code needed (see example below where I selected a dataset to classify tweets in categories).\\n\\nReal world impact: Missing in Chicago won a Pulitzer using a similar approach - 200 volunteers labeled police misconduct files to train their model. That's the power of good data annotation.\\n\\nThree immediate use cases I see:\\n- Build collaborative training sets with your community (surprisingly underused in AI journalism)\\n- Turn your website chatbot logs into high-quality fine-tuning data\\n- Compare generated vs published content (great for SEO headlines)\\n\\nWorks for solo projects or teams up to 100 people. All integrated with HuggingFace Hub for immediate model training.\\n\\nInteresting to see tools like this making data quality more accessible. Data quality is the hidden driver of AI success that we don't talk about enough.\\n\\n- Check out the blogpost: https://huggingface.co/blog/argilla-ui-hub\\n- And the quickstart guide: https://docs.argilla.io/latest/getting_started/quickstart/\\n\\n\",\n",
       "   'publishedAt': '2024-11-05T15:30:30.000Z',\n",
       "   'author': 'fdaudens'},\n",
       "  {'content': 'üö®üî• New Release Alert! üî•üö®\\n\\nIntroducing the 435M model that outperforms Llama-Guard-3-8B while slashing 75% of the computation cost! üíªüí•\\nüëâ Check it out: https://huggingface.co/hbseong/HarmAug-Guard (Yes, INFERENCE CODE INCLUDED! üí°)\\n\\nMore details in our paper: https://arxiv.org/abs/2410.01524 üìú\\n\\n#HarmAug #LLM # Safety #EfficiencyBoost #Research #AI #MachineLearning ',\n",
       "   'publishedAt': '2024-11-06T06:56:19.000Z',\n",
       "   'author': 'hbseong'},\n",
       "  {'content': '\\U0001faf5üëæ LM Studio is hiring engineers who know the ins and outs of NodeJS & want to work on local LLMs. \\n\\nKnow anyone who might be interested?\\n\\nApply here:  https://docs.google.com/forms/d/e/1FAIpQLSc_786-_i_q4fo5ESqYnNyjIH0B5Rs45QIwejd_NV5AjNDZ7A/viewform',\n",
       "   'publishedAt': '2024-11-05T15:39:44.000Z',\n",
       "   'author': 'yagilb'},\n",
       "  {'content': 'ùóõùòÇùóªùòÜùòÇùóÆùóª-ùóüùóÆùóøùó¥ùó≤ ùó∑ùòÇùòÄùòÅ ùóøùó≤ùóπùó≤ùóÆùòÄùó≤ùó± ùóØùòÜ ùóßùó≤ùóªùó∞ùó≤ùóªùòÅ: ùóüùóÆùóøùó¥ùó≤ùòÄùòÅ ùó≤ùòÉùó≤ùóø ùóºùóΩùó≤ùóª ùó†ùóºùóò ùóüùóüùó†, ùóºùóªùóπùòÜ ùü±ùüÆùóï ùóÆùó∞ùòÅùó∂ùòÉùó≤ ùóΩùóÆùóøùóÆùó∫ùó≤ùòÅùó≤ùóøùòÄ ùóØùòÇùòÅ ùóØùó≤ùóÆùòÅùòÄ ùóüùóüùóÆùó†ùóî ùüØ.ùü≠-ùü∞ùü¨ùü±ùóï ùóºùóª ùó∫ùóºùòÄùòÅ ùóÆùó∞ùóÆùó±ùó≤ùó∫ùó∂ùó∞ ùóØùó≤ùóªùó∞ùóµùó∫ùóÆùóøùó∏ùòÄ üöÄ\\n\\n‚ö° Mixture of Experts (MoE) architecture: 389 B parameters in total, but only 52B are activated for any input\\n\\nüß™ Trained on 7T tokens, including 1.5T tokens of synthetic data\\n\\nüèóÔ∏è Architecture : Novel \"recycle routing\" prevents token dropping when experts are overrloaded\\n\\nüìä Great benchmark results: Surpasses Llama-3-405B-Instruct in most benchmarks although it has 8x fewer active parameters\\n‚Ä£ Impressive perf on MATH: 77.4\\n\\nüêã\\xa0Large context length: up to 256K tokens\\n\\nüîí License:\\n‚Ä£ Commercial use allowed, except if your products have >100M monthly active users\\n‚Ä£ No access in the EU\\n\\nü§ó\\xa0Model weights available on HF!\\n\\nRead the full paper here üëâ\\xa0https://huggingface.co/papers/2411.02265',\n",
       "   'publishedAt': '2024-11-05T09:36:47.000Z',\n",
       "   'author': 'm-ric'},\n",
       "  {'content': \"New Droppingsü•≥\\n\\nüò∂\\u200düå´Ô∏èCollection: https://huggingface.co/collections/prithivMLmods/flux-lora-collections-66dd5908be2206cfaa8519be\\n\\nü•≥Demo Here: https://huggingface.co/spaces/prithivMLmods/FLUX-LoRA-DLC  with more than 100+ Flux LoRA's\\n\\nü™®Fluid Dramatic Neon: https://huggingface.co/prithivMLmods/Castor-Dramatic-Neon-Flux-LoRA\\nü™®Past & Present Blend: https://huggingface.co/prithivMLmods/Past-Present-Deep-Mix-Flux-LoRA\\nü™®Tarot Cards Refreshed Themes: https://huggingface.co/prithivMLmods/Ton618-Tarot-Cards-Flux-LoRA\\nü™®Amxtoon Character Mix Real-Anime: https://huggingface.co/prithivMLmods/Ton618-Amxtoon-Flux-LoRA\\nü™®Epic Realism Flux v1: https://huggingface.co/prithivMLmods/Ton618-Epic-Realism-Flux-LoRA\\nü™®Mock-up Textures: https://huggingface.co/prithivMLmods/Mockup-Texture-Flux-LoRA\\n.\\n.\\n.\\n@prithivMLmods ü§ó\",\n",
       "   'publishedAt': '2024-10-30T14:24:17.000Z',\n",
       "   'author': 'prithivMLmods'},\n",
       "  {'content': 'Are you familiar with the difference between discrete learning and predictive learning? This distinction is exactly why LLM models are not designed to perform and execute function calls, they are not the right shape for it. LLM models are prediction machines. Function calling requires discrete learning machines. Fortunately, you can easily couple an LLM model with a discrete learning algorithm. It is beyond easy to do, you simply need to know the math to do it. Want to dive deeper into this subject? Check out this video.\\n\\nhttps://youtu.be/wBRem2p8iPM',\n",
       "   'publishedAt': '2024-11-06T23:03:05.000Z',\n",
       "   'author': 'TuringsSolutions'}]}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trend_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bjss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
